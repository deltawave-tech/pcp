module @turbine {
  func.func @main(%arg0: tensor<1x8xi64>, %arg1: tensor<1x8xi64>) -> tensor<f32> attributes {torch.args_schema = "[1, {\22type\22: \22builtins.tuple\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: \22builtins.list\22, \22context\22: \22null\22, \22children_spec\22: [{\22type\22: null, \22context\22: null, \22children_spec\22: []}, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]}, {\22type\22: \22builtins.dict\22, \22context\22: \22[]\22, \22children_spec\22: []}]}]", torch.return_schema = "[1, {\22type\22: null, \22context\22: null, \22children_spec\22: []}]"} {
    %0 = torch_c.from_builtin_tensor %arg0 : tensor<1x8xi64> -> !torch.vtensor<[1,8],si64>
    %1 = torch_c.from_builtin_tensor %arg1 : tensor<1x8xi64> -> !torch.vtensor<[1,8],si64>
    %2 = call @forward(%0, %1) : (!torch.vtensor<[1,8],si64>, !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[],f32>
    %3 = torch_c.to_builtin_tensor %2 : !torch.vtensor<[],f32> -> tensor<f32>
    return %3 : tensor<f32>
  }
  func.func private @forward(%arg0: !torch.vtensor<[1,8],si64>, %arg1: !torch.vtensor<[1,8],si64>) -> !torch.vtensor<[],f32> {
    %0 = torch.vtensor.literal(dense_resource<torch_tensor_65_32_torch.float32> : tensor<65x32xf32>) : !torch.vtensor<[65,32],f32>
    %int-1 = torch.constant.int -1
    %false = torch.constant.bool false
    %false_0 = torch.constant.bool false
    %1 = torch.aten.embedding %0, %arg0, %int-1, %false, %false_0 : !torch.vtensor<[65,32],f32>, !torch.vtensor<[1,8],si64>, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[1,8,32],f32>
    %int8 = torch.constant.int 8
    %int4 = torch.constant.int 4
    %none = torch.constant.none
    %cpu = torch.constant.device "cpu"
    %false_1 = torch.constant.bool false
    %2 = torch.aten.arange %int8, %int4, %none, %cpu, %false_1 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[8],si64>
    %3 = torch.vtensor.literal(dense_resource<torch_tensor_8_32_torch.float32> : tensor<8x32xf32>) : !torch.vtensor<[8,32],f32>
    %int-1_2 = torch.constant.int -1
    %false_3 = torch.constant.bool false
    %false_4 = torch.constant.bool false
    %4 = torch.aten.embedding %3, %2, %int-1_2, %false_3, %false_4 : !torch.vtensor<[8,32],f32>, !torch.vtensor<[8],si64>, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[8,32],f32>
    %int1 = torch.constant.int 1
    %5 = torch.aten.add.Tensor %1, %4, %int1 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[8,32],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int2 = torch.constant.int 2
    %6 = torch.prim.ListConstruct %int2 : (!torch.int) -> !torch.list<int>
    %int0 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %5, %6, %int0, %true : !torch.vtensor<[1,8,32],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,8,1],f32>, !torch.vtensor<[1,8,1],f32>
    %float1.000000e-05 = torch.constant.float 1.000000e-05
    %int1_5 = torch.constant.int 1
    %7 = torch.aten.add.Scalar %result0, %float1.000000e-05, %int1_5 : !torch.vtensor<[1,8,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,8,1],f32>
    %8 = torch.aten.rsqrt %7 : !torch.vtensor<[1,8,1],f32> -> !torch.vtensor<[1,8,1],f32>
    %int1_6 = torch.constant.int 1
    %9 = torch.aten.sub.Tensor %5, %result1, %int1_6 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,1],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %10 = torch.aten.mul.Tensor %9, %8 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,1],f32> -> !torch.vtensor<[1,8,32],f32>
    %11 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %12 = torch.aten.mul.Tensor %10, %11 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[32],f32> -> !torch.vtensor<[1,8,32],f32>
    %13 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32_1> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %int1_7 = torch.constant.int 1
    %14 = torch.aten.add.Tensor %12, %13, %int1_7 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[32],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int8_8 = torch.constant.int 8
    %int32 = torch.constant.int 32
    %15 = torch.prim.ListConstruct %int8_8, %int32 : (!torch.int, !torch.int) -> !torch.list<int>
    %16 = torch.aten.view %14, %15 : !torch.vtensor<[1,8,32],f32>, !torch.list<int> -> !torch.vtensor<[8,32],f32>
    %17 = torch.vtensor.literal(dense_resource<torch_tensor_96_32_torch.float32> : tensor<96x32xf32>) : !torch.vtensor<[96,32],f32>
    %int0_9 = torch.constant.int 0
    %int1_10 = torch.constant.int 1
    %18 = torch.aten.transpose.int %17, %int0_9, %int1_10 : !torch.vtensor<[96,32],f32>, !torch.int, !torch.int -> !torch.vtensor<[32,96],f32>
    %19 = torch.aten.mm %16, %18 : !torch.vtensor<[8,32],f32>, !torch.vtensor<[32,96],f32> -> !torch.vtensor<[8,96],f32>
    %int1_11 = torch.constant.int 1
    %20 = torch.aten.mul.Scalar %19, %int1_11 : !torch.vtensor<[8,96],f32>, !torch.int -> !torch.vtensor<[8,96],f32>
    %21 = torch.vtensor.literal(dense_resource<torch_tensor_96_torch.float32> : tensor<96xf32>) : !torch.vtensor<[96],f32>
    %int1_12 = torch.constant.int 1
    %22 = torch.aten.mul.Scalar %21, %int1_12 : !torch.vtensor<[96],f32>, !torch.int -> !torch.vtensor<[96],f32>
    %int1_13 = torch.constant.int 1
    %23 = torch.aten.add.Tensor %20, %22, %int1_13 : !torch.vtensor<[8,96],f32>, !torch.vtensor<[96],f32>, !torch.int -> !torch.vtensor<[8,96],f32>
    %int1_14 = torch.constant.int 1
    %int8_15 = torch.constant.int 8
    %int96 = torch.constant.int 96
    %24 = torch.prim.ListConstruct %int1_14, %int8_15, %int96 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %25 = torch.aten.view %23, %24 : !torch.vtensor<[8,96],f32>, !torch.list<int> -> !torch.vtensor<[1,8,96],f32>
    %int1_16 = torch.constant.int 1
    %int8_17 = torch.constant.int 8
    %int32_18 = torch.constant.int 32
    %26 = torch.prim.ListConstruct %int1_16, %int8_17, %int32_18 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %int768 = torch.constant.int 768
    %int96_19 = torch.constant.int 96
    %int1_20 = torch.constant.int 1
    %27 = torch.prim.ListConstruct %int768, %int96_19, %int1_20 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %int0_21 = torch.constant.int 0
    %28 = torch.aten.as_strided %25, %26, %27, %int0_21 : !torch.vtensor<[1,8,96],f32>, !torch.list<int>, !torch.list<int>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int1_22 = torch.constant.int 1
    %int8_23 = torch.constant.int 8
    %int32_24 = torch.constant.int 32
    %29 = torch.prim.ListConstruct %int1_22, %int8_23, %int32_24 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %int768_25 = torch.constant.int 768
    %int96_26 = torch.constant.int 96
    %int1_27 = torch.constant.int 1
    %30 = torch.prim.ListConstruct %int768_25, %int96_26, %int1_27 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %int32_28 = torch.constant.int 32
    %31 = torch.aten.as_strided %25, %29, %30, %int32_28 : !torch.vtensor<[1,8,96],f32>, !torch.list<int>, !torch.list<int>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int1_29 = torch.constant.int 1
    %int8_30 = torch.constant.int 8
    %int32_31 = torch.constant.int 32
    %32 = torch.prim.ListConstruct %int1_29, %int8_30, %int32_31 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %int768_32 = torch.constant.int 768
    %int96_33 = torch.constant.int 96
    %int1_34 = torch.constant.int 1
    %33 = torch.prim.ListConstruct %int768_32, %int96_33, %int1_34 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %int64 = torch.constant.int 64
    %34 = torch.aten.as_strided %25, %32, %33, %int64 : !torch.vtensor<[1,8,96],f32>, !torch.list<int>, !torch.list<int>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int1_35 = torch.constant.int 1
    %int8_36 = torch.constant.int 8
    %int4_37 = torch.constant.int 4
    %int8_38 = torch.constant.int 8
    %35 = torch.prim.ListConstruct %int1_35, %int8_36, %int4_37, %int8_38 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %36 = torch.aten.view %31, %35 : !torch.vtensor<[1,8,32],f32>, !torch.list<int> -> !torch.vtensor<[1,8,4,8],f32>
    %int1_39 = torch.constant.int 1
    %int2_40 = torch.constant.int 2
    %37 = torch.aten.transpose.int %36, %int1_39, %int2_40 : !torch.vtensor<[1,8,4,8],f32>, !torch.int, !torch.int -> !torch.vtensor<[1,4,8,8],f32>
    %int1_41 = torch.constant.int 1
    %int8_42 = torch.constant.int 8
    %int4_43 = torch.constant.int 4
    %int8_44 = torch.constant.int 8
    %38 = torch.prim.ListConstruct %int1_41, %int8_42, %int4_43, %int8_44 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %39 = torch.aten.view %28, %38 : !torch.vtensor<[1,8,32],f32>, !torch.list<int> -> !torch.vtensor<[1,8,4,8],f32>
    %int1_45 = torch.constant.int 1
    %int2_46 = torch.constant.int 2
    %40 = torch.aten.transpose.int %39, %int1_45, %int2_46 : !torch.vtensor<[1,8,4,8],f32>, !torch.int, !torch.int -> !torch.vtensor<[1,4,8,8],f32>
    %int1_47 = torch.constant.int 1
    %int8_48 = torch.constant.int 8
    %int4_49 = torch.constant.int 4
    %int8_50 = torch.constant.int 8
    %41 = torch.prim.ListConstruct %int1_47, %int8_48, %int4_49, %int8_50 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %42 = torch.aten.view %34, %41 : !torch.vtensor<[1,8,32],f32>, !torch.list<int> -> !torch.vtensor<[1,8,4,8],f32>
    %int1_51 = torch.constant.int 1
    %int2_52 = torch.constant.int 2
    %43 = torch.aten.transpose.int %42, %int1_51, %int2_52 : !torch.vtensor<[1,8,4,8],f32>, !torch.int, !torch.int -> !torch.vtensor<[1,4,8,8],f32>
    %int-2 = torch.constant.int -2
    %int-1_53 = torch.constant.int -1
    %44 = torch.aten.transpose.int %37, %int-2, %int-1_53 : !torch.vtensor<[1,4,8,8],f32>, !torch.int, !torch.int -> !torch.vtensor<[1,4,8,8],f32>
    %int1_54 = torch.constant.int 1
    %int4_55 = torch.constant.int 4
    %int8_56 = torch.constant.int 8
    %int8_57 = torch.constant.int 8
    %45 = torch.prim.ListConstruct %int1_54, %int4_55, %int8_56, %int8_57 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_58 = torch.constant.bool false
    %46 = torch.aten.expand %40, %45, %false_58 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,4,8,8],f32>
    %int4_59 = torch.constant.int 4
    %int8_60 = torch.constant.int 8
    %int8_61 = torch.constant.int 8
    %47 = torch.prim.ListConstruct %int4_59, %int8_60, %int8_61 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %48 = torch.aten.view %46, %47 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int> -> !torch.vtensor<[4,8,8],f32>
    %int1_62 = torch.constant.int 1
    %int4_63 = torch.constant.int 4
    %int8_64 = torch.constant.int 8
    %int8_65 = torch.constant.int 8
    %49 = torch.prim.ListConstruct %int1_62, %int4_63, %int8_64, %int8_65 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_66 = torch.constant.bool false
    %50 = torch.aten.expand %44, %49, %false_66 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,4,8,8],f32>
    %int4_67 = torch.constant.int 4
    %int8_68 = torch.constant.int 8
    %int8_69 = torch.constant.int 8
    %51 = torch.prim.ListConstruct %int4_67, %int8_68, %int8_69 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %52 = torch.aten.view %50, %51 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int> -> !torch.vtensor<[4,8,8],f32>
    %53 = torch.aten.bmm %48, %52 : !torch.vtensor<[4,8,8],f32>, !torch.vtensor<[4,8,8],f32> -> !torch.vtensor<[4,8,8],f32>
    %int1_70 = torch.constant.int 1
    %int4_71 = torch.constant.int 4
    %int8_72 = torch.constant.int 8
    %int8_73 = torch.constant.int 8
    %54 = torch.prim.ListConstruct %int1_70, %int4_71, %int8_72, %int8_73 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %55 = torch.aten.view %53, %54 : !torch.vtensor<[4,8,8],f32>, !torch.list<int> -> !torch.vtensor<[1,4,8,8],f32>
    %float3.535530e-01 = torch.constant.float 0.35355339059327373
    %56 = torch.aten.mul.Scalar %55, %float3.535530e-01 : !torch.vtensor<[1,4,8,8],f32>, !torch.float -> !torch.vtensor<[1,4,8,8],f32>
    %57 = torch.vtensor.literal(dense_resource<torch_tensor_1_1_8_8_torch.float32> : tensor<1x1x8x8xf32>) : !torch.vtensor<[1,1,8,8],f32>
    %int0_74 = torch.constant.int 0
    %int0_75 = torch.constant.int 0
    %int9223372036854775807 = torch.constant.int 9223372036854775807
    %int1_76 = torch.constant.int 1
    %58 = torch.aten.slice.Tensor %57, %int0_74, %int0_75, %int9223372036854775807, %int1_76 : !torch.vtensor<[1,1,8,8],f32>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[1,1,8,8],f32>
    %int1_77 = torch.constant.int 1
    %int0_78 = torch.constant.int 0
    %int9223372036854775807_79 = torch.constant.int 9223372036854775807
    %int1_80 = torch.constant.int 1
    %59 = torch.aten.slice.Tensor %58, %int1_77, %int0_78, %int9223372036854775807_79, %int1_80 : !torch.vtensor<[1,1,8,8],f32>, !torch.int, !torch.int, !torch.int, !torch.int -> !torch.vtensor<[1,1,8,8],f32>
    %int0_81 = torch.constant.int 0
    %60 = torch.aten.eq.Scalar %59, %int0_81 : !torch.vtensor<[1,1,8,8],f32>, !torch.int -> !torch.vtensor<[1,1,8,8],i1>
    %float-Inf = torch.constant.float 0xFFF0000000000000
    %int6 = torch.constant.int 6
    %int0_82 = torch.constant.int 0
    %cpu_83 = torch.constant.device "cpu"
    %none_84 = torch.constant.none
    %61 = torch.aten.scalar_tensor %float-Inf, %int6, %int0_82, %cpu_83, %none_84 : !torch.float, !torch.int, !torch.int, !torch.Device, !torch.none -> !torch.vtensor<[],f32>
    %62 = torch.aten.where.self %60, %61, %56 : !torch.vtensor<[1,1,8,8],i1>, !torch.vtensor<[],f32>, !torch.vtensor<[1,4,8,8],f32> -> !torch.vtensor<[1,4,8,8],f32>
    %int-1_85 = torch.constant.int -1
    %false_86 = torch.constant.bool false
    %63 = torch.aten._softmax %62, %int-1_85, %false_86 : !torch.vtensor<[1,4,8,8],f32>, !torch.int, !torch.bool -> !torch.vtensor<[1,4,8,8],f32>
    %64 = torch.aten.detach %63 : !torch.vtensor<[1,4,8,8],f32> -> !torch.vtensor<[1,4,8,8],f32>
    %int1_87 = torch.constant.int 1
    %int4_88 = torch.constant.int 4
    %int8_89 = torch.constant.int 8
    %int8_90 = torch.constant.int 8
    %65 = torch.prim.ListConstruct %int1_87, %int4_88, %int8_89, %int8_90 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_91 = torch.constant.bool false
    %66 = torch.aten.expand %63, %65, %false_91 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,4,8,8],f32>
    %int4_92 = torch.constant.int 4
    %int8_93 = torch.constant.int 8
    %int8_94 = torch.constant.int 8
    %67 = torch.prim.ListConstruct %int4_92, %int8_93, %int8_94 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %68 = torch.aten.view %66, %67 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int> -> !torch.vtensor<[4,8,8],f32>
    %int1_95 = torch.constant.int 1
    %int4_96 = torch.constant.int 4
    %int8_97 = torch.constant.int 8
    %int8_98 = torch.constant.int 8
    %69 = torch.prim.ListConstruct %int1_95, %int4_96, %int8_97, %int8_98 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_99 = torch.constant.bool false
    %70 = torch.aten.expand %43, %69, %false_99 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,4,8,8],f32>
    %int4_100 = torch.constant.int 4
    %int8_101 = torch.constant.int 8
    %int8_102 = torch.constant.int 8
    %71 = torch.prim.ListConstruct %int4_100, %int8_101, %int8_102 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %72 = torch.aten.view %70, %71 : !torch.vtensor<[1,4,8,8],f32>, !torch.list<int> -> !torch.vtensor<[4,8,8],f32>
    %73 = torch.aten.bmm %68, %72 : !torch.vtensor<[4,8,8],f32>, !torch.vtensor<[4,8,8],f32> -> !torch.vtensor<[4,8,8],f32>
    %int1_103 = torch.constant.int 1
    %int4_104 = torch.constant.int 4
    %int8_105 = torch.constant.int 8
    %int8_106 = torch.constant.int 8
    %74 = torch.prim.ListConstruct %int1_103, %int4_104, %int8_105, %int8_106 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %75 = torch.aten.view %73, %74 : !torch.vtensor<[4,8,8],f32>, !torch.list<int> -> !torch.vtensor<[1,4,8,8],f32>
    %int1_107 = torch.constant.int 1
    %int2_108 = torch.constant.int 2
    %76 = torch.aten.transpose.int %75, %int1_107, %int2_108 : !torch.vtensor<[1,4,8,8],f32>, !torch.int, !torch.int -> !torch.vtensor<[1,8,4,8],f32>
    %int0_109 = torch.constant.int 0
    %77 = torch.aten.clone %76, %int0_109 : !torch.vtensor<[1,8,4,8],f32>, !torch.int -> !torch.vtensor<[1,8,4,8],f32>
    %int1_110 = torch.constant.int 1
    %int8_111 = torch.constant.int 8
    %int32_112 = torch.constant.int 32
    %78 = torch.prim.ListConstruct %int1_110, %int8_111, %int32_112 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %79 = torch.aten.view %77, %78 : !torch.vtensor<[1,8,4,8],f32>, !torch.list<int> -> !torch.vtensor<[1,8,32],f32>
    %int8_113 = torch.constant.int 8
    %int32_114 = torch.constant.int 32
    %80 = torch.prim.ListConstruct %int8_113, %int32_114 : (!torch.int, !torch.int) -> !torch.list<int>
    %81 = torch.aten.view %79, %80 : !torch.vtensor<[1,8,32],f32>, !torch.list<int> -> !torch.vtensor<[8,32],f32>
    %82 = torch.vtensor.literal(dense_resource<torch_tensor_32_32_torch.float32> : tensor<32x32xf32>) : !torch.vtensor<[32,32],f32>
    %int0_115 = torch.constant.int 0
    %int1_116 = torch.constant.int 1
    %83 = torch.aten.transpose.int %82, %int0_115, %int1_116 : !torch.vtensor<[32,32],f32>, !torch.int, !torch.int -> !torch.vtensor<[32,32],f32>
    %84 = torch.aten.mm %81, %83 : !torch.vtensor<[8,32],f32>, !torch.vtensor<[32,32],f32> -> !torch.vtensor<[8,32],f32>
    %int1_117 = torch.constant.int 1
    %85 = torch.aten.mul.Scalar %84, %int1_117 : !torch.vtensor<[8,32],f32>, !torch.int -> !torch.vtensor<[8,32],f32>
    %86 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32_2> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %int1_118 = torch.constant.int 1
    %87 = torch.aten.mul.Scalar %86, %int1_118 : !torch.vtensor<[32],f32>, !torch.int -> !torch.vtensor<[32],f32>
    %int1_119 = torch.constant.int 1
    %88 = torch.aten.add.Tensor %85, %87, %int1_119 : !torch.vtensor<[8,32],f32>, !torch.vtensor<[32],f32>, !torch.int -> !torch.vtensor<[8,32],f32>
    %int1_120 = torch.constant.int 1
    %int8_121 = torch.constant.int 8
    %int32_122 = torch.constant.int 32
    %89 = torch.prim.ListConstruct %int1_120, %int8_121, %int32_122 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %90 = torch.aten.view %88, %89 : !torch.vtensor<[8,32],f32>, !torch.list<int> -> !torch.vtensor<[1,8,32],f32>
    %int1_123 = torch.constant.int 1
    %91 = torch.aten.add.Tensor %5, %90, %int1_123 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,32],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int2_124 = torch.constant.int 2
    %92 = torch.prim.ListConstruct %int2_124 : (!torch.int) -> !torch.list<int>
    %int0_125 = torch.constant.int 0
    %true_126 = torch.constant.bool true
    %result0_127, %result1_128 = torch.aten.var_mean.correction %91, %92, %int0_125, %true_126 : !torch.vtensor<[1,8,32],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,8,1],f32>, !torch.vtensor<[1,8,1],f32>
    %float1.000000e-05_129 = torch.constant.float 1.000000e-05
    %int1_130 = torch.constant.int 1
    %93 = torch.aten.add.Scalar %result0_127, %float1.000000e-05_129, %int1_130 : !torch.vtensor<[1,8,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,8,1],f32>
    %94 = torch.aten.rsqrt %93 : !torch.vtensor<[1,8,1],f32> -> !torch.vtensor<[1,8,1],f32>
    %int1_131 = torch.constant.int 1
    %95 = torch.aten.sub.Tensor %91, %result1_128, %int1_131 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,1],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %96 = torch.aten.mul.Tensor %95, %94 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,1],f32> -> !torch.vtensor<[1,8,32],f32>
    %97 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32_3> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %98 = torch.aten.mul.Tensor %96, %97 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[32],f32> -> !torch.vtensor<[1,8,32],f32>
    %99 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32_4> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %int1_132 = torch.constant.int 1
    %100 = torch.aten.add.Tensor %98, %99, %int1_132 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[32],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int8_133 = torch.constant.int 8
    %int32_134 = torch.constant.int 32
    %101 = torch.prim.ListConstruct %int8_133, %int32_134 : (!torch.int, !torch.int) -> !torch.list<int>
    %102 = torch.aten.view %100, %101 : !torch.vtensor<[1,8,32],f32>, !torch.list<int> -> !torch.vtensor<[8,32],f32>
    %103 = torch.vtensor.literal(dense_resource<torch_tensor_128_32_torch.float32> : tensor<128x32xf32>) : !torch.vtensor<[128,32],f32>
    %int0_135 = torch.constant.int 0
    %int1_136 = torch.constant.int 1
    %104 = torch.aten.transpose.int %103, %int0_135, %int1_136 : !torch.vtensor<[128,32],f32>, !torch.int, !torch.int -> !torch.vtensor<[32,128],f32>
    %105 = torch.aten.mm %102, %104 : !torch.vtensor<[8,32],f32>, !torch.vtensor<[32,128],f32> -> !torch.vtensor<[8,128],f32>
    %int1_137 = torch.constant.int 1
    %106 = torch.aten.mul.Scalar %105, %int1_137 : !torch.vtensor<[8,128],f32>, !torch.int -> !torch.vtensor<[8,128],f32>
    %107 = torch.vtensor.literal(dense_resource<torch_tensor_128_torch.float32> : tensor<128xf32>) : !torch.vtensor<[128],f32>
    %int1_138 = torch.constant.int 1
    %108 = torch.aten.mul.Scalar %107, %int1_138 : !torch.vtensor<[128],f32>, !torch.int -> !torch.vtensor<[128],f32>
    %int1_139 = torch.constant.int 1
    %109 = torch.aten.add.Tensor %106, %108, %int1_139 : !torch.vtensor<[8,128],f32>, !torch.vtensor<[128],f32>, !torch.int -> !torch.vtensor<[8,128],f32>
    %int1_140 = torch.constant.int 1
    %int8_141 = torch.constant.int 8
    %int128 = torch.constant.int 128
    %110 = torch.prim.ListConstruct %int1_140, %int8_141, %int128 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %111 = torch.aten.view %109, %110 : !torch.vtensor<[8,128],f32>, !torch.list<int> -> !torch.vtensor<[1,8,128],f32>
    %112 = torch.aten.relu %111 : !torch.vtensor<[1,8,128],f32> -> !torch.vtensor<[1,8,128],f32>
    %113 = torch.aten.detach %112 : !torch.vtensor<[1,8,128],f32> -> !torch.vtensor<[1,8,128],f32>
    %int8_142 = torch.constant.int 8
    %int128_143 = torch.constant.int 128
    %114 = torch.prim.ListConstruct %int8_142, %int128_143 : (!torch.int, !torch.int) -> !torch.list<int>
    %115 = torch.aten.view %112, %114 : !torch.vtensor<[1,8,128],f32>, !torch.list<int> -> !torch.vtensor<[8,128],f32>
    %116 = torch.vtensor.literal(dense_resource<torch_tensor_32_128_torch.float32> : tensor<32x128xf32>) : !torch.vtensor<[32,128],f32>
    %int0_144 = torch.constant.int 0
    %int1_145 = torch.constant.int 1
    %117 = torch.aten.transpose.int %116, %int0_144, %int1_145 : !torch.vtensor<[32,128],f32>, !torch.int, !torch.int -> !torch.vtensor<[128,32],f32>
    %118 = torch.aten.mm %115, %117 : !torch.vtensor<[8,128],f32>, !torch.vtensor<[128,32],f32> -> !torch.vtensor<[8,32],f32>
    %int1_146 = torch.constant.int 1
    %119 = torch.aten.mul.Scalar %118, %int1_146 : !torch.vtensor<[8,32],f32>, !torch.int -> !torch.vtensor<[8,32],f32>
    %120 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32_5> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %int1_147 = torch.constant.int 1
    %121 = torch.aten.mul.Scalar %120, %int1_147 : !torch.vtensor<[32],f32>, !torch.int -> !torch.vtensor<[32],f32>
    %int1_148 = torch.constant.int 1
    %122 = torch.aten.add.Tensor %119, %121, %int1_148 : !torch.vtensor<[8,32],f32>, !torch.vtensor<[32],f32>, !torch.int -> !torch.vtensor<[8,32],f32>
    %int1_149 = torch.constant.int 1
    %int8_150 = torch.constant.int 8
    %int32_151 = torch.constant.int 32
    %123 = torch.prim.ListConstruct %int1_149, %int8_150, %int32_151 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %124 = torch.aten.view %122, %123 : !torch.vtensor<[8,32],f32>, !torch.list<int> -> !torch.vtensor<[1,8,32],f32>
    %int1_152 = torch.constant.int 1
    %125 = torch.aten.add.Tensor %91, %124, %int1_152 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,32],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int2_153 = torch.constant.int 2
    %126 = torch.prim.ListConstruct %int2_153 : (!torch.int) -> !torch.list<int>
    %int0_154 = torch.constant.int 0
    %true_155 = torch.constant.bool true
    %result0_156, %result1_157 = torch.aten.var_mean.correction %125, %126, %int0_154, %true_155 : !torch.vtensor<[1,8,32],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,8,1],f32>, !torch.vtensor<[1,8,1],f32>
    %float1.000000e-05_158 = torch.constant.float 1.000000e-05
    %int1_159 = torch.constant.int 1
    %127 = torch.aten.add.Scalar %result0_156, %float1.000000e-05_158, %int1_159 : !torch.vtensor<[1,8,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,8,1],f32>
    %128 = torch.aten.rsqrt %127 : !torch.vtensor<[1,8,1],f32> -> !torch.vtensor<[1,8,1],f32>
    %int1_160 = torch.constant.int 1
    %129 = torch.aten.sub.Tensor %125, %result1_157, %int1_160 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,1],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %130 = torch.aten.mul.Tensor %129, %128 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[1,8,1],f32> -> !torch.vtensor<[1,8,32],f32>
    %131 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32_6> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %132 = torch.aten.mul.Tensor %130, %131 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[32],f32> -> !torch.vtensor<[1,8,32],f32>
    %133 = torch.vtensor.literal(dense_resource<torch_tensor_32_torch.float32_7> : tensor<32xf32>) : !torch.vtensor<[32],f32>
    %int1_161 = torch.constant.int 1
    %134 = torch.aten.add.Tensor %132, %133, %int1_161 : !torch.vtensor<[1,8,32],f32>, !torch.vtensor<[32],f32>, !torch.int -> !torch.vtensor<[1,8,32],f32>
    %int8_162 = torch.constant.int 8
    %int32_163 = torch.constant.int 32
    %135 = torch.prim.ListConstruct %int8_162, %int32_163 : (!torch.int, !torch.int) -> !torch.list<int>
    %136 = torch.aten.view %134, %135 : !torch.vtensor<[1,8,32],f32>, !torch.list<int> -> !torch.vtensor<[8,32],f32>
    %137 = torch.vtensor.literal(dense_resource<torch_tensor_65_32_torch.float32_1> : tensor<65x32xf32>) : !torch.vtensor<[65,32],f32>
    %int0_164 = torch.constant.int 0
    %int1_165 = torch.constant.int 1
    %138 = torch.aten.transpose.int %137, %int0_164, %int1_165 : !torch.vtensor<[65,32],f32>, !torch.int, !torch.int -> !torch.vtensor<[32,65],f32>
    %139 = torch.aten.mm %136, %138 : !torch.vtensor<[8,32],f32>, !torch.vtensor<[32,65],f32> -> !torch.vtensor<[8,65],f32>
    %int1_166 = torch.constant.int 1
    %140 = torch.aten.mul.Scalar %139, %int1_166 : !torch.vtensor<[8,65],f32>, !torch.int -> !torch.vtensor<[8,65],f32>
    %141 = torch.vtensor.literal(dense_resource<torch_tensor_65_torch.float32> : tensor<65xf32>) : !torch.vtensor<[65],f32>
    %int1_167 = torch.constant.int 1
    %142 = torch.aten.mul.Scalar %141, %int1_167 : !torch.vtensor<[65],f32>, !torch.int -> !torch.vtensor<[65],f32>
    %int1_168 = torch.constant.int 1
    %143 = torch.aten.add.Tensor %140, %142, %int1_168 : !torch.vtensor<[8,65],f32>, !torch.vtensor<[65],f32>, !torch.int -> !torch.vtensor<[8,65],f32>
    %int1_169 = torch.constant.int 1
    %int8_170 = torch.constant.int 8
    %int65 = torch.constant.int 65
    %144 = torch.prim.ListConstruct %int1_169, %int8_170, %int65 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %145 = torch.aten.view %143, %144 : !torch.vtensor<[8,65],f32>, !torch.list<int> -> !torch.vtensor<[1,8,65],f32>
    %int-1_171 = torch.constant.int -1
    %int65_172 = torch.constant.int 65
    %146 = torch.prim.ListConstruct %int-1_171, %int65_172 : (!torch.int, !torch.int) -> !torch.list<int>
    %147 = torch.aten.view %145, %146 : !torch.vtensor<[1,8,65],f32>, !torch.list<int> -> !torch.vtensor<[8,65],f32>
    %int-1_173 = torch.constant.int -1
    %148 = torch.prim.ListConstruct %int-1_173 : (!torch.int) -> !torch.list<int>
    %149 = torch.aten.view %arg1, %148 : !torch.vtensor<[1,8],si64>, !torch.list<int> -> !torch.vtensor<[8],si64>
    %int1_174 = torch.constant.int 1
    %150 = torch.prim.ListConstruct %int1_174 : (!torch.int) -> !torch.list<int>
    %true_175 = torch.constant.bool true
    %151 = torch.aten.amax %147, %150, %true_175 : !torch.vtensor<[8,65],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[8,1],f32>
    %int1_176 = torch.constant.int 1
    %152 = torch.aten.sub.Tensor %147, %151, %int1_176 : !torch.vtensor<[8,65],f32>, !torch.vtensor<[8,1],f32>, !torch.int -> !torch.vtensor<[8,65],f32>
    %153 = torch.aten.exp %152 : !torch.vtensor<[8,65],f32> -> !torch.vtensor<[8,65],f32>
    %int1_177 = torch.constant.int 1
    %154 = torch.prim.ListConstruct %int1_177 : (!torch.int) -> !torch.list<int>
    %true_178 = torch.constant.bool true
    %none_179 = torch.constant.none
    %155 = torch.aten.sum.dim_IntList %153, %154, %true_178, %none_179 : !torch.vtensor<[8,65],f32>, !torch.list<int>, !torch.bool, !torch.none -> !torch.vtensor<[8,1],f32>
    %156 = torch.aten.log %155 : !torch.vtensor<[8,1],f32> -> !torch.vtensor<[8,1],f32>
    %int1_180 = torch.constant.int 1
    %157 = torch.aten.sub.Tensor %152, %156, %int1_180 : !torch.vtensor<[8,65],f32>, !torch.vtensor<[8,1],f32>, !torch.int -> !torch.vtensor<[8,65],f32>
    %158 = torch.aten.detach %157 : !torch.vtensor<[8,65],f32> -> !torch.vtensor<[8,65],f32>
    %int-100 = torch.constant.int -100
    %159 = torch.aten.ne.Scalar %149, %int-100 : !torch.vtensor<[8],si64>, !torch.int -> !torch.vtensor<[8],i1>
    %int0_181 = torch.constant.int 0
    %int4_182 = torch.constant.int 4
    %int0_183 = torch.constant.int 0
    %cpu_184 = torch.constant.device "cpu"
    %none_185 = torch.constant.none
    %160 = torch.aten.scalar_tensor %int0_181, %int4_182, %int0_183, %cpu_184, %none_185 : !torch.int, !torch.int, !torch.int, !torch.Device, !torch.none -> !torch.vtensor<[],si64>
    %161 = torch.aten.where.self %159, %149, %160 : !torch.vtensor<[8],i1>, !torch.vtensor<[8],si64>, !torch.vtensor<[],si64> -> !torch.vtensor<[8],si64>
    %int1_186 = torch.constant.int 1
    %162 = torch.aten.unsqueeze %161, %int1_186 : !torch.vtensor<[8],si64>, !torch.int -> !torch.vtensor<[8,1],si64>
    %int1_187 = torch.constant.int 1
    %false_188 = torch.constant.bool false
    %163 = torch.aten.gather %157, %int1_187, %162, %false_188 : !torch.vtensor<[8,65],f32>, !torch.int, !torch.vtensor<[8,1],si64>, !torch.bool -> !torch.vtensor<[8,1],f32>
    %int1_189 = torch.constant.int 1
    %164 = torch.aten.squeeze.dim %163, %int1_189 : !torch.vtensor<[8,1],f32>, !torch.int -> !torch.vtensor<[8],f32>
    %165 = torch.aten.neg %164 : !torch.vtensor<[8],f32> -> !torch.vtensor<[8],f32>
    %int-100_190 = torch.constant.int -100
    %166 = torch.aten.ne.Scalar %149, %int-100_190 : !torch.vtensor<[8],si64>, !torch.int -> !torch.vtensor<[8],i1>
    %int0_191 = torch.constant.int 0
    %int6_192 = torch.constant.int 6
    %int0_193 = torch.constant.int 0
    %cpu_194 = torch.constant.device "cpu"
    %none_195 = torch.constant.none
    %167 = torch.aten.scalar_tensor %int0_191, %int6_192, %int0_193, %cpu_194, %none_195 : !torch.int, !torch.int, !torch.int, !torch.Device, !torch.none -> !torch.vtensor<[],f32>
    %168 = torch.aten.where.self %166, %165, %167 : !torch.vtensor<[8],i1>, !torch.vtensor<[8],f32>, !torch.vtensor<[],f32> -> !torch.vtensor<[8],f32>
    %int-100_196 = torch.constant.int -100
    %169 = torch.aten.ne.Scalar %149, %int-100_196 : !torch.vtensor<[8],si64>, !torch.int -> !torch.vtensor<[8],i1>
    %none_197 = torch.constant.none
    %170 = torch.aten.sum %169, %none_197 : !torch.vtensor<[8],i1>, !torch.none -> !torch.vtensor<[],si64>
    %int6_198 = torch.constant.int 6
    %171 = torch.prims.convert_element_type %170, %int6_198 : !torch.vtensor<[],si64>, !torch.int -> !torch.vtensor<[],f32>
    %none_199 = torch.constant.none
    %172 = torch.aten.sum %168, %none_199 : !torch.vtensor<[8],f32>, !torch.none -> !torch.vtensor<[],f32>
    %173 = torch.aten.div.Tensor %172, %171 : !torch.vtensor<[],f32>, !torch.vtensor<[],f32> -> !torch.vtensor<[],f32>
    return %173 : !torch.vtensor<[],f32>
  }
}

{-#

#-}
