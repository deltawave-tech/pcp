const std = @import("std");
const mlir = @import("mlir.zig");
const c = @import("mlir/c.zig").c;

const Allocator = std.mem.Allocator;

const TILING_TRANSFORM_SCRIPT =
    \\module attributes { transform.with_named_sequence } {
    \\  transform.named_sequence @__transform_main(%arg0: !transform.any_op) {
    \\    transform.sequence %arg0 : !transform.any_op failures(propagate) {
    \\      ^bb1(%arg1: !transform.any_op):
    \\        %matmul = transform.structured.match ops{["linalg.generic"]} attributes {iterator_types = ["parallel", "parallel", "parallel", "reduction"]} in %arg1 : (!transform.any_op) -> !transform.any_op
    \\        %init_or_alloc_op, %more_parallel_fill_op, %split_matmul, %combining_linalg_op = transform.structured.split_reduction %matmul {split_factor = 8, insert_split_dimension = 3} : (!transform.any_op) -> (!transform.any_op, !transform.any_op, !transform.any_op, !transform.any_op)
    \\        %tiled_split, %forall_split = transform.structured.tile_using_forall %split_matmul tile_sizes [4, 32, 32, 8, 0]
    \\          (mapping = [#gpu.block<x>, #gpu.block<y>, #gpu.thread<x>, #gpu.thread<y>]) : (!transform.any_op) -> (!transform.any_op, !transform.any_op)
    \\        %tiled_fill, %forall_fill = transform.structured.tile_using_forall %more_parallel_fill_op tile_sizes [4, 32, 32, 8]
    \\          (mapping = [#gpu.block<x>, #gpu.block<y>, #gpu.thread<x>, #gpu.thread<y>]) : (!transform.any_op) -> (!transform.any_op, !transform.any_op)
    \\        %tiled_combine, %forall_combine = transform.structured.tile_using_forall %combining_linalg_op tile_sizes [4, 32, 32]
    \\          (mapping = [#gpu.block<x>, #gpu.block<y>, #gpu.thread<x>]) : (!transform.any_op) -> (!transform.any_op, !transform.any_op)
    \\    }
    \\    transform.yield
    \\  }
    \\}
;

const GPU_MAPPING_SCRIPT =
    \\module attributes { transform.with_named_sequence } {
    \\  transform.named_sequence @__transform_main(%arg0: !transform.any_op) {
    \\    %func = transform.structured.match ops{["func.func"]} in %arg0 : (!transform.any_op) -> !transform.any_op
    \\    transform.gpu.map_forall_to_blocks %func { generate_gpu_launch } : (!transform.any_op) -> !transform.any_op
    \\    transform.gpu.map_nested_forall_to_threads %func block_dims = [32, 8, 1] sync_after_distribute = false warp_size = 1 : (!transform.any_op) -> !transform.any_op
    \\    transform.yield
    \\  }
    \\}
;

/// MLIR Context wrapper for StableHLO → GPU → SPIR-V pipeline
pub const MLIRContext = struct {
    allocator: Allocator,
    context: *c.MlirContext,
    registry: ?*c.MlirDialectRegistry,
    
    // --- REMOVED ---
    // pass_manager: mlir.PassManager, // <-- This field is the source of the state bug. Remove it.
    
    const Self = @This();
    
    pub fn init(allocator: Allocator) !Self {
        std.debug.print("MLIRContext.init: Creating IREE-backed MLIR context...\n", .{});
        const context = c.contextCreate();
        c.contextSetAllowUnregisteredDialects(context, true);

        // --- START OF THE FIX ---
        // Instead of relying on automatic discovery, we will now explicitly
        // register and load the dialects we need.

        // 1. Create a dialect registry.
        const registry = c.dialectRegistryCreate();
        defer c.dialectRegistryDestroy(registry);
        
        // 2. Insert the dialects we need into the registry.
        //    This calls the C functions generated by our new pass_anchors.cpp
        std.debug.print("Inserting dialects into registry...\n", .{});
        c.mlirDialectHandleInsertDialect(c.mlirGetDialectHandle__func__(), registry);
        c.mlirDialectHandleInsertDialect(c.mlirGetDialectHandle__stablehlo__(), registry);
        c.mlirDialectHandleInsertDialect(c.mlirGetDialectHandle__arith__(), registry);

        // 3. Append the configured registry to the context.
        std.debug.print("Appending registry to context...\n", .{});
        c.contextAppendDialectRegistry(context, registry);
        
        // 4. Also try loading all available dialects as fallback
        std.debug.print("Loading all available dialects...\n", .{});
        c.contextLoadAllAvailableDialects(context);
        // --- END OF THE FIX ---

        // Now, our check will succeed because we have explicitly loaded the dialect.
        std.debug.print("Checking if stablehlo.constant operation is registered...\n", .{});
        if (!c.contextIsRegisteredOperation(context, "stablehlo.constant")) {
            // Try alternative operation names
            std.debug.print("stablehlo.constant not found, trying stablehlo.add...\n", .{});
            if (!c.contextIsRegisteredOperation(context, "stablehlo.add")) {
                std.log.err("FATAL: Stablehlo dialect not registered. Check IREE build and linking.", .{});
                return error.DialectRegistrationFailed;
            }
        }
        std.debug.print("StableHLO dialect successfully registered!\n", .{});
        
        return Self{
            .allocator = allocator,
            .context = context,
            .registry = null, // We are not managing the registry after appending it.
        };
    }
    
    /// Create an MLIRContext wrapper from an existing MLIR context
    /// This avoids double initialization when sharing contexts between components
    pub fn fromContext(context: mlir.Context) Self {
        // Create a minimal wrapper that doesn't own the context
        // The registry is set to null since we're not managing it
        return Self{
            .allocator = std.heap.page_allocator, // Dummy allocator since we're not managing resources
            .context = context.handle,
            .registry = null, // Not managing the registry
        };
    }
    
    pub fn deinit(self: *Self) void {
        // self.pass_manager.deinit(); // <-- Remove this.
        if (self.registry) |registry| {
            c.dialectRegistryDestroy(registry);
        }
        // Only destroy context if we own it (registry is not null)
        if (self.registry != null) {
            c.contextDestroy(self.context);
        }
    }
    
    /// Compiles an MLIR module to a VMFB artifact using the IREE compiler.
    pub fn compileToVMFB(self: *Self, allocator: Allocator, module: mlir.Module, iree_target: []const u8) ![]u8 {
        _ = self; // Not using self directly, but good practice for a method

        // 1. Serialize MLIR module to a string
        const mlir_source = try serializeMLIRModule(allocator, module);
        defer allocator.free(mlir_source);

        // 2. Create unique temporary file paths to avoid race conditions
        const timestamp = std.time.timestamp();
        const temp_mlir_path = try std.fmt.allocPrint(allocator, "/tmp/pcp_module_{d}.mlir", .{timestamp});
        defer allocator.free(temp_mlir_path);
        const temp_vmfb_path = try std.fmt.allocPrint(allocator, "/tmp/pcp_module_{d}.vmfb", .{timestamp});
        defer allocator.free(temp_vmfb_path);
        
        // Defer cleanup of temp files
        defer std.fs.deleteFileAbsolute(temp_mlir_path) catch {};
        defer std.fs.deleteFileAbsolute(temp_vmfb_path) catch {};

        // 3. Write MLIR to temporary file
        try std.fs.cwd().writeFile(.{ .sub_path = temp_mlir_path, .data = mlir_source });

        // 4. Call the IREE compiler as a subprocess
        // This path assumes your `pcp` project and `iree-build` directory are siblings.
        const iree_compile_path = "../iree-build/tools/iree-compile";

        // FIX: Build the target argument string at runtime
        const target_arg = try std.fmt.allocPrint(allocator, "--iree-hal-target-backends={s}", .{iree_target});
        defer allocator.free(target_arg);

        const result = std.process.Child.run(.{
            .allocator = allocator,
            .argv = &.{
                iree_compile_path,
                temp_mlir_path,
                target_arg,
                "-o",
                temp_vmfb_path,
            },
        }) catch |err| {
            std.log.err("Failed to execute `iree-compile`: {s}", .{@errorName(err)});
            std.log.err("Ensure IREE is built correctly in the ../iree-build directory.", .{});
            return err;
        };
        defer allocator.free(result.stdout);
        defer allocator.free(result.stderr);

        if (result.term != .Exited or result.term.Exited != 0) {
            std.log.err("IREE compilation failed with stdout:\n{s}", .{result.stdout});
            std.log.err("IREE compilation failed with stderr:\n{s}", .{result.stderr});
            std.log.err("Problematic MLIR source was written to: {s}", .{temp_mlir_path});
            // Note: We don't delete the file on error so you can inspect it.
            return error.IREECompilationFailed;
        }

        // 5. Read the compiled VMFB artifact back into memory
        const vmfb_binary = try std.fs.cwd().readFileAlloc(allocator, temp_vmfb_path, 50 * 1024 * 1024); // 50MB limit
        return vmfb_binary;
    }
    
    /// NEW IREE-based SPIR-V compilation replacing the complex manual pipeline
    pub fn lowerToSPIRV(_: *Self, allocator: Allocator, module: mlir.Module, unique_id: u32) ![]const u8 {
        // 1. Serialize MLIR module to file for IREE compilation
        const mlir_source = serializeMLIRModule(allocator, module) catch |err| {
            return err;
        };
        defer allocator.free(mlir_source);
        
        // --- START: MODIFICATION ---

        // DEFINITIVE FIX: Use shorter paths and the /tmp directory to avoid filesystem path length limits.
        // IREE generates very long filenames, so we need shorter base directory names.
        const temp_mlir_path = try std.fmt.allocPrint(allocator, "/tmp/g{d}.mlir", .{unique_id});
        defer allocator.free(temp_mlir_path);
        const temp_vmfb_path = try std.fmt.allocPrint(allocator, "/tmp/g{d}.vmfb", .{unique_id});
        defer allocator.free(temp_vmfb_path);
        const spirv_dump_dir = try std.fmt.allocPrint(allocator, "/tmp/spv{d}", .{unique_id});
        defer allocator.free(spirv_dump_dir);
        
        // Write MLIR to temporary file using absolute path
        var file = try std.fs.createFileAbsolute(temp_mlir_path, .{});
        defer file.close();
        try file.writeAll(mlir_source);
        
        std.fs.makeDirAbsolute(spirv_dump_dir) catch |err| {
            if (err != error.PathAlreadyExists) {
                return err;
            }
        };
        
        // --- END: MODIFICATION ---
        
        // 2. Call IREE compiler via subprocess
        
        const result = std.process.Child.run(.{
            .allocator = allocator,
            .argv = &.{
                "python3",
                "iree_compile_wrapper.py",
                temp_mlir_path,
                temp_vmfb_path,
                spirv_dump_dir,
                "vulkan-spirv"
            },
        }) catch |err| {
            std.debug.print("ERROR: Failed to run IREE compiler: {}\n", .{err});
            std.debug.print("This might indicate IREE is not installed or python3 is not available\n", .{});
            std.debug.print("Dumping MLIR module for debugging:\n", .{});
            module.op().dump();
            
            // Check if we can at least call python3
            const python_test = std.process.Child.run(.{
                .allocator = allocator,
                .argv = &.{ "python3", "--version" },
            }) catch |py_err| {
                std.debug.print("ERROR: python3 not found: {}\n", .{py_err});
                return error.Python3NotFound;
            };
            defer {
                allocator.free(python_test.stdout);
                allocator.free(python_test.stderr);
            }
            
            return error.IREESubprocessFailed;
        };
        
        
        defer {
            allocator.free(result.stdout);
            allocator.free(result.stderr);
        }
        
        if (result.term != .Exited or result.term.Exited != 0) {
            std.log.err("IREE compilation failed: {s}", .{result.stderr});
            std.debug.print("Dumping MLIR module for debugging:\n", .{});
            module.op().dump();
            return error.IREECompilationFailed;
        }
        
        
        // 3. Find and read the generated SPIR-V file(s)
        var spirv_dir = std.fs.openDirAbsolute(spirv_dump_dir, .{ .iterate = true }) catch {
            return error.SPIRVDumpDirNotFound;
        };
        defer spirv_dir.close();
        
        var iterator = spirv_dir.iterate();
        var spirv_binary: ?[]const u8 = null;
        
        while (try iterator.next()) |entry| {
            if (entry.kind == .file and std.mem.endsWith(u8, entry.name, ".spv")) {
                spirv_binary = try spirv_dir.readFileAlloc(allocator, entry.name, 10 * 1024 * 1024);
                break; // Use first SPIR-V file found
            }
        }
        
        // Clean up the unique temporary files and directory using absolute paths
        std.fs.deleteFileAbsolute(temp_mlir_path) catch {};
        std.fs.deleteFileAbsolute(temp_vmfb_path) catch {};
        std.fs.deleteDirAbsolute(spirv_dump_dir) catch {};
        
        if (spirv_binary == null) {
            std.debug.print("ERROR: No SPIR-V files were generated by IREE\n", .{});
            return error.NoSPIRVGenerated;
        }
        
        std.debug.print("✓ Successfully extracted SPIR-V binary ({} bytes)\n", .{spirv_binary.?.len});
        return spirv_binary.?;
    }
    
    /// Translates a module containing SPIR-V dialect ops into a SPIR-V binary blob
    pub fn translateToSPIRV(self: *Self, module: mlir.Module) ![]const u8 {
        var spirv_binary = std.ArrayList(u8).init(self.allocator);
        
        const result = c.translateModuleToSPIRV(module.handle, &writeToArrayList, &spirv_binary);
        if (mlir.isFailure(result)) {
            spirv_binary.deinit();
            return error.MLIRTranslationFailed;
        }
        
        std.debug.print("✓ Successfully translated module to SPIR-V binary ({} bytes)\n", .{spirv_binary.items.len});
        std.debug.print(">>> Real SPIR-V binary size: {} bytes (stub was 20 bytes)\n", .{spirv_binary.items.len});
        return spirv_binary.toOwnedSlice();
    }
    
    /// Extracts the names of all generated GPU kernels from a lowered module
    /// You need these names to launch the kernels from your Metal runtime
    pub fn getGpuKernelNames(self: *Self, module: mlir.Module) ![][]const u8 {
        var names = std.ArrayList([]const u8).init(self.allocator);
        
        var walk_ctx = WalkContext{ .alloc = self.allocator, .list = &names };
        
        c.operationWalk(module.op().handle, &kernelNameExtractor, &walk_ctx);
        
        const result = names.toOwnedSlice();
        std.debug.print("✓ Extracted {} GPU kernel names from module\n", .{names.items.len});
        return result;
    }
    
    /// Get the MLIR context handle for creating modules
    pub fn getContext(self: *Self) mlir.Context {
        return mlir.Context{ .handle = self.context };
    }
    
    const WalkContext = struct {
        alloc: Allocator,
        list: *std.ArrayList([]const u8),
    };
    
    // Callback for mlirOperationWalk to extract GPU kernel names
    fn kernelNameExtractor(op: *c.MlirOperation, userData: ?*anyopaque) callconv(.C) c.MlirWalkResult {
        const walk_ctx: *anyopaque = userData.?;
        const ctx = @as(*const WalkContext, @ptrCast(@alignCast(walk_ctx))).*;
        
        // Check if the operation is a `gpu.func`. This is the MLIR representation
        // of a GPU kernel.
        const op_name_id = c.operationGetName(op);
        const op_name_ref = c.identifierStr(op_name_id);
        const op_name = c.fromStringRef(op_name_ref);
        
        if (std.mem.eql(u8, op_name, "gpu.func")) {
            // The kernel name is stored in the `sym_name` attribute.
            const attr = c.operationGetAttributeByName(op, "sym_name");
            if (@intFromPtr(attr) != 0 and c.attributeIsAString(attr)) {
                const string_attr = @as(*c.MlirStringAttribute, @ptrCast(attr));
                const sym_name_ref = c.stringAttributeGetValue(string_attr);
                const sym_name = c.fromStringRef(sym_name_ref);
                
                const owned_name = ctx.alloc.dupe(u8, sym_name) catch |err| {
                    std.debug.print("Failed to allocate kernel name: {}\n", .{err});
                    return .Interrupt;
                };
                
                ctx.list.append(owned_name) catch |err| {
                    std.debug.print("Failed to append kernel name: {}\n", .{err});
                    return .Interrupt;
                };
            }
        }
        return .Advance;
    }
    
    // Callback for translateModuleToSPIRV to collect SPIR-V binary data
    fn writeToArrayList(ref: c.MlirStringRef, userData: ?*anyopaque) callconv(.C) void {
        const list = @as(*std.ArrayList(u8), @ptrCast(@alignCast(userData.?)));
        const data = c.fromStringRef(ref);
        list.appendSlice(data) catch {};
    }
};

/// Serialize an MLIR module to a string representation for network transfer.
pub fn serializeMLIRModule(allocator: Allocator, module: mlir.Module) ![]u8 {
    std.debug.print("serializeMLIRModule: Creating buffer...\n", .{});
    var buffer = std.ArrayList(u8).init(allocator);
    var serialization_error = false;
    
    const SerializationContext = struct {
        buffer: *std.ArrayList(u8),
        error_flag: *bool,
    };
    
    var ctx = SerializationContext{
        .buffer = &buffer,
        .error_flag = &serialization_error,
    };
    
    const writeToArrayList = struct {
        fn callback(data_ptr: [*]const u8, data_len: usize, userData: ?*anyopaque) callconv(.C) void {
            const context = @as(*SerializationContext, @ptrCast(@alignCast(userData.?)));
            const data = data_ptr[0..data_len];
            
            std.debug.print("MLIR serialization callback: appending {} bytes (total so far: {})\n", .{ data_len, context.buffer.items.len });
            
            // Add bounds checking to prevent buffer overflow
            if (data_len > 100 * 1024 * 1024) { // 100MB sanity check
                std.debug.print("ERROR: MLIR serialization data chunk too large: {} bytes\n", .{data_len});
                context.error_flag.* = true;
                return;
            }
            context.buffer.appendSlice(data) catch |err| {
                std.debug.print("ERROR: Failed to append MLIR data chunk of {} bytes: {}\n", .{ data_len, err });
                context.error_flag.* = true;
                return;
            };
        }
    }.callback;

    std.debug.print("serializeMLIRModule: About to call mlirOperationPrint...\n", .{});
    // Add null checks
    const module_op = module.op();
    if (@intFromPtr(module_op.handle) == 0) {
        std.debug.print("ERROR: Module operation handle is null\n", .{});
        return error.NullModuleHandle;
    }
    
    c.mlirOperationPrint(module_op.handle, writeToArrayList, &ctx);
    std.debug.print("serializeMLIRModule: mlirOperationPrint completed, buffer size: {}\n", .{buffer.items.len});
    
    // Check if any errors occurred during serialization
    if (serialization_error) {
        std.debug.print("ERROR: MLIR serialization failed due to callback errors\n", .{});
        buffer.deinit();
        return error.MLIRSerializationFailed;
    }
    
    const serialized = buffer.toOwnedSlice() catch |err| {
        std.debug.print("ERROR: Failed to convert buffer to owned slice: {}\n", .{err});
        return err;
    };
    std.debug.print("✓ Serialized MLIR module to {} bytes\n", .{serialized.len});
    return serialized;
}

/// Deserialize an MLIR module from a string representation.
pub fn deserializeMLIRModule(allocator: Allocator, context: mlir.Context, data: []const u8) !mlir.Module {
    _ = allocator;
    
    std.debug.print("deserializeMLIRModule: About to parse {} bytes of MLIR data...\n", .{data.len});
    
    // Check if context is valid
    if (@intFromPtr(context.handle) == 0) {
        std.debug.print("ERROR: MLIR context handle is null in deserialization!\n", .{});
        return error.NullContextHandle;
    }
    std.debug.print("✓ MLIR context handle is valid: 0x{x}\n", .{@intFromPtr(context.handle)});
    
    // Show first 200 chars of MLIR data for debugging
    const preview_len = @min(200, data.len);
    std.debug.print("MLIR data preview ({} chars): {s}\n", .{ preview_len, data[0..preview_len] });
    
    // Also show data around line 870 where the error occurs
    if (data.len > 870) {
        std.debug.print("Investigating line 870 error - looking for problematic area...\n", .{});
        
        // Find approximate line 870 (assuming ~80 chars per line average)
        const approx_char_pos = 870 * 80;
        const start_pos = if (approx_char_pos > 100) approx_char_pos - 100 else 0;
        const end_pos = @min(approx_char_pos + 200, data.len);
        
        if (start_pos < data.len) {
            std.debug.print("Data around estimated line 870 (chars {}-{}): {s}\n", .{ start_pos, end_pos, data[start_pos..end_pos] });
        }
        
        // Look for null bytes or invalid characters
        var null_count: usize = 0;
        var first_null: ?usize = null;
        for (data, 0..) |byte, i| {
            if (byte == 0) {
                null_count += 1;
                if (first_null == null) first_null = i;
            }
        }
        
        if (null_count > 0) {
            std.debug.print("WARNING: Found {} null bytes in MLIR data! First at position {}\n", .{ null_count, first_null.? });
        }
    }
    
    const module = mlir.Module.parse(context, data) catch |err| {
        std.debug.print("ERROR: mlir.Module.parse failed: {}\n", .{err});
        return err;
    };
    
    std.debug.print("✓ mlir.Module.parse completed, checking module handle...\n", .{});
    if (@intFromPtr(module.handle) == 0) {
        std.debug.print("ERROR: Parsed module has null handle!\n", .{});
        return error.NullParsedModuleHandle;
    }
    std.debug.print("✓ Parsed module handle is valid: 0x{x}\n", .{@intFromPtr(module.handle)});
    
    // Check operation handle immediately
    const test_op = module.op();
    if (@intFromPtr(test_op.handle) == 0) {
        std.debug.print("ERROR: Module operation handle is null after parsing!\n", .{});
        return error.NullOperationHandle;
    }
    std.debug.print("✓ Module operation handle is valid: 0x{x}\n", .{@intFromPtr(test_op.handle)});
    
    std.debug.print("✓ Deserialized MLIR module from {} bytes\n", .{data.len});
    return module;
}

/// SPIR-V to Metal Shading Language (MSL) translator using SPIRV-Cross
pub fn translateSpirvToMsl(allocator: Allocator, spirv_binary: []const u8) ![]u8 {
    var msl_source = std.ArrayList(u8).init(allocator);
    
    // Use SPIRV-Cross to translate SPIR-V to MSL
    const result = c.translateSPIRVToMSL(
        spirv_binary.ptr,
        spirv_binary.len,
        &MLIRContext.writeToArrayList,
        &msl_source
    );
    
    if (mlir.isFailure(result)) {
        msl_source.deinit();
        // Fallback to template if SPIRV-Cross fails
        std.debug.print("⚠ SPIRV-Cross translation failed, using template MSL\n", .{});
        const msl_template = 
            \\#include <metal_stdlib>
            \\using namespace metal;
            \\
            \\// Template MSL kernel (SPIRV-Cross translation failed)
            \\kernel void gpu_kernel_add(device const float* input0 [[buffer(0)]],
            \\                          device const float* input1 [[buffer(1)]],
            \\                          device float* output [[buffer(2)]],
            \\                          uint index [[thread_position_in_grid]]) {
            \\    output[index] = input0[index] + input1[index];
            \\}
        ;
        return try allocator.dupe(u8, msl_template);
    }
    
    const msl_result = try msl_source.toOwnedSlice();
    std.debug.print("✓ Translated SPIR-V to MSL using SPIRV-Cross ({} bytes → {} bytes)\n", .{ spirv_binary.len, msl_result.len });
    return msl_result;
}

/// GPU Kernel metadata extracted from MLIR GPU dialect
pub const GPUKernelInfo = struct {
    name: []const u8,
    grid_size: [3]usize,
    block_size: [3]usize,
    
    pub fn deinit(self: *GPUKernelInfo, allocator: Allocator) void {
        allocator.free(self.name);
    }
};

/// Extract kernel names from SPIR-V binary using SPIRV-Cross
pub fn extractKernelNamesFromSPIRV(allocator: Allocator, spirv_binary: []const u8) ![][]const u8 {
    var c_names: [*][*:0]const u8 = undefined;
    const count = c.extractKernelNamesFromSPIRV(spirv_binary, &c_names);
    defer c.freeKernelNames(c_names, count);

    if (count == 0) {
        std.debug.print("⚠ No GPU kernels found in SPIR-V binary\n", .{});
        // Return empty array
        return try allocator.alloc([]const u8, 0);
    }

    const names = try allocator.alloc([]const u8, count);
    for (0..count) |i| {
        const kernel_name = std.mem.span(c_names[i]);
        names[i] = try allocator.dupe(u8, kernel_name);
    }
    
    std.debug.print("✓ Extracted {} GPU kernel names from SPIR-V binary\n", .{names.len});
    return names;
}

/// Extract GPU kernel metadata from SPIR-V binary using SPIRV-Cross
pub fn extractGPUKernelInfo(allocator: Allocator, spirv_binary: []const u8) ![]GPUKernelInfo {
    // NEW IMPLEMENTATION: Extract names directly from the SPIR-V binary
    var c_names: [*][*:0]const u8 = undefined;
    const count = c.extractKernelNamesFromSPIRV(spirv_binary, &c_names);
    defer c.freeKernelNames(c_names, count);

    if (count == 0) {
        std.debug.print("⚠ No GPU kernels found in SPIR-V binary, using fallback\n", .{});
        // Fallback to demo kernel info if no kernels found
        const kernels = try allocator.alloc(GPUKernelInfo, 1);
        kernels[0] = GPUKernelInfo{
            .name = try allocator.dupe(u8, "fallback_kernel"),
            .grid_size = [3]usize{ 1, 1, 1 },
            .block_size = [3]usize{ 256, 1, 1 },
        };
        return kernels;
    }

    const kernels = try allocator.alloc(GPUKernelInfo, count);
    for (0..count) |i| {
        const kernel_name = std.mem.span(c_names[i]);
        kernels[i] = GPUKernelInfo{
            .name = try allocator.dupe(u8, kernel_name),
            // NOTE: We can't get grid/block size from SPIR-V.
            // This metadata is lost when we leave the MLIR ecosystem.
            // We must use a sensible default or determine it at runtime.
            .grid_size = [3]usize{ 1, 1, 1 },
            .block_size = [3]usize{ 256, 1, 1 },
        };
    }
    
    std.debug.print("✓ Extracted {} GPU kernel names from SPIR-V binary\n", .{kernels.len});
    return kernels;
}

