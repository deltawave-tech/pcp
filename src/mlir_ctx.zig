const std = @import("std");
const mlir = @import("mlir.zig");
const c = @import("mlir/c.zig").c;

const Allocator = std.mem.Allocator;

const TILING_TRANSFORM_SCRIPT =
    \\module attributes { transform.with_named_sequence } {
    \\  transform.named_sequence @__transform_main(%arg0: !transform.any_op) {
    \\    transform.sequence %arg0 : !transform.any_op failures(propagate) {
    \\      ^bb1(%arg1: !transform.any_op):
    \\        %matmul = transform.structured.match ops{["linalg.generic"]} attributes {iterator_types = ["parallel", "parallel", "parallel", "reduction"]} in %arg1 : (!transform.any_op) -> !transform.any_op
    \\        %init_or_alloc_op, %more_parallel_fill_op, %split_matmul, %combining_linalg_op = transform.structured.split_reduction %matmul {split_factor = 8, insert_split_dimension = 3} : (!transform.any_op) -> (!transform.any_op, !transform.any_op, !transform.any_op, !transform.any_op)
    \\        %tiled_split, %forall_split = transform.structured.tile_using_forall %split_matmul tile_sizes [4, 32, 32, 8, 0]
    \\          (mapping = [#gpu.block<x>, #gpu.block<y>, #gpu.thread<x>, #gpu.thread<y>]) : (!transform.any_op) -> (!transform.any_op, !transform.any_op)
    \\        %tiled_fill, %forall_fill = transform.structured.tile_using_forall %more_parallel_fill_op tile_sizes [4, 32, 32, 8]
    \\          (mapping = [#gpu.block<x>, #gpu.block<y>, #gpu.thread<x>, #gpu.thread<y>]) : (!transform.any_op) -> (!transform.any_op, !transform.any_op)
    \\        %tiled_combine, %forall_combine = transform.structured.tile_using_forall %combining_linalg_op tile_sizes [4, 32, 32]
    \\          (mapping = [#gpu.block<x>, #gpu.block<y>, #gpu.thread<x>]) : (!transform.any_op) -> (!transform.any_op, !transform.any_op)
    \\    }
    \\    transform.yield
    \\  }
    \\}
;

const GPU_MAPPING_SCRIPT =
    \\module attributes { transform.with_named_sequence } {
    \\  transform.named_sequence @__transform_main(%arg0: !transform.any_op) {
    \\    %func = transform.structured.match ops{["func.func"]} in %arg0 : (!transform.any_op) -> !transform.any_op
    \\    transform.gpu.map_forall_to_blocks %func { generate_gpu_launch } : (!transform.any_op) -> !transform.any_op
    \\    transform.gpu.map_nested_forall_to_threads %func block_dims = [32, 8, 1] sync_after_distribute = false warp_size = 1 : (!transform.any_op) -> !transform.any_op
    \\    transform.yield
    \\  }
    \\}
;

/// MLIR Context wrapper for StableHLO → GPU → SPIR-V pipeline
pub const MLIRContext = struct {
    allocator: Allocator,
    context: c.MlirContext,
    registry: ?c.MlirDialectRegistry,
    
    // --- REMOVED ---
    // pass_manager: mlir.PassManager, // <-- This field is the source of the state bug. Remove it.
    
    const Self = @This();
    
    pub fn init(allocator: Allocator) !Self {
        std.debug.print("MLIRContext.init: Creating IREE-backed MLIR context...\n", .{});
        const context = c.contextCreate();
        c.contextSetAllowUnregisteredDialects(context, true);

        // --- START OF THE FIX ---
        // Instead of relying on automatic discovery, we will now explicitly
        // register and load the dialects we need.

        // 1. Create a dialect registry.
        const registry = c.dialectRegistryCreate();
        defer c.dialectRegistryDestroy(registry);
        
        // 2. Insert the dialects we need into the registry.
        //    This calls the C functions generated by our new pass_anchors.cpp
        std.debug.print("Inserting dialects into registry...\n", .{});
        c.mlirDialectHandleInsertDialect(c.mlirGetDialectHandle__func__(), registry);
        c.mlirDialectHandleInsertDialect(c.mlirGetDialectHandle__stablehlo__(), registry);
        c.mlirDialectHandleInsertDialect(c.mlirGetDialectHandle__arith__(), registry);

        // 3. Append the configured registry to the context.
        std.debug.print("Appending registry to context...\n", .{});
        c.contextAppendDialectRegistry(context, registry);
        
        // 4. Also try loading all available dialects as fallback
        std.debug.print("Loading all available dialects...\n", .{});
        c.contextLoadAllAvailableDialects(context);
        // --- END OF THE FIX ---

        // Now, our check will succeed because we have explicitly loaded the dialect.
        std.debug.print("Checking if stablehlo.constant operation is registered...\n", .{});
        const constant_name = c.stringRefFromString("stablehlo.constant");
        if (!c.contextIsRegisteredOperation(context, constant_name)) {
            // Try alternative operation names
            std.debug.print("stablehlo.constant not found, trying stablehlo.add...\n", .{});
            const add_name = c.stringRefFromString("stablehlo.add");
            if (!c.contextIsRegisteredOperation(context, add_name)) {
                std.log.err("FATAL: Stablehlo dialect not registered. Check IREE build and linking.", .{});
                return error.DialectRegistrationFailed;
            }
        }
        std.debug.print("StableHLO dialect successfully registered!\n", .{});
        
        return Self{
            .allocator = allocator,
            .context = context,
            .registry = null, // We are not managing the registry after appending it.
        };
    }
    
    /// Create an MLIRContext wrapper from an existing MLIR context
    /// This avoids double initialization when sharing contexts between components
    pub fn fromContext(context: mlir.Context) Self {
        // Create a minimal wrapper that doesn't own the context
        // The registry is set to null since we're not managing it
        return Self{
            .allocator = std.heap.page_allocator, // Dummy allocator since we're not managing resources
            .context = context.handle,
            .registry = null, // Not managing the registry
        };
    }
    
    pub fn deinit(self: *Self) void {
        // self.pass_manager.deinit(); // <-- Remove this.
        if (self.registry) |registry| {
            c.dialectRegistryDestroy(registry);
        }
        // Only destroy context if we own it (registry is not null)
        if (self.registry != null) {
            c.contextDestroy(self.context);
        }
    }
    
    /// Compiles an MLIR module to a VMFB artifact using the IREE compiler.
    pub fn compileToVMFB(self: *Self, allocator: Allocator, mlir_source: []const u8, iree_target: []const u8) ![]u8 {
        _ = self; // Not using self directly

        // 1. No need to serialize anymore, we already have the source!

        // 2. Create unique temporary file paths to avoid race conditions
        const timestamp = std.time.timestamp();
        const temp_mlir_path = try std.fmt.allocPrint(allocator, "/tmp/pcp_module_{d}.mlir", .{timestamp});
        defer allocator.free(temp_mlir_path);
        const temp_vmfb_path = try std.fmt.allocPrint(allocator, "/tmp/pcp_module_{d}.vmfb", .{timestamp});
        defer allocator.free(temp_vmfb_path);

        // 3. Write MLIR to temporary file
        try std.fs.cwd().writeFile(.{ .sub_path = temp_mlir_path, .data = mlir_source });

        // 4. Call the IREE compiler as a subprocess
        // This path assumes your `pcp` project and `iree-build` directory are siblings.
        const iree_compile_path = "../iree-build/tools/iree-compile";

        // FIX: Build the target argument string at runtime
        const target_arg = try std.fmt.allocPrint(allocator, "--iree-hal-target-backends={s}", .{iree_target});
        defer allocator.free(target_arg);

        const result = std.process.Child.run(.{
            .allocator = allocator,
            .argv = &.{
                iree_compile_path,
                temp_mlir_path,
                target_arg,
                // Disable vector distribution passes for CUDA to avoid distribution errors
                // Both flags are needed to prevent the "failed to distribute" error
                "--iree-codegen-llvmgpu-use-vector-distribution=false",
                "--iree-codegen-llvmgpu-use-reduction-vector-distribution=false",
                "-o",
                temp_vmfb_path,
            },
        }) catch |err| {
            std.log.err("Failed to execute `iree-compile`: {s}", .{@errorName(err)});
            std.log.err("Ensure IREE is built correctly in the ../iree-build directory.", .{});
            return err;
        };
        defer allocator.free(result.stdout);
        defer allocator.free(result.stderr);

        if (result.term != .Exited or result.term.Exited != 0) {
            std.log.err("IREE compilation failed with stdout:\n{s}", .{result.stdout});
            std.log.err("IREE compilation failed with stderr:\n{s}", .{result.stderr});
            std.log.err("Problematic MLIR source was written to: {s}", .{temp_mlir_path});
            // Note: We don't delete the file on error so you can inspect it.
            return error.IREECompilationFailed;
        }

        // 5. Read the compiled VMFB artifact back into memory
        const vmfb_binary = try std.fs.cwd().readFileAlloc(allocator, temp_vmfb_path, 50 * 1024 * 1024); // 50MB limit

        // Clean up temporary files on success
        std.fs.deleteFileAbsolute(temp_mlir_path) catch {};
        std.fs.deleteFileAbsolute(temp_vmfb_path) catch {};

        return vmfb_binary;
    }

    /// Get the MLIR context handle for creating modules
    pub fn getContext(self: *Self) mlir.Context {
        return mlir.Context{ .handle = self.context };
    }
};

/// Serialize an MLIR module to a string representation for network transfer.
pub fn serializeMLIRModule(allocator: Allocator, module: mlir.Module) ![]u8 {
    // Debug: std.debug.print("serializeMLIRModule: Creating buffer...\n", .{});
    var buffer = std.ArrayList(u8).init(allocator);
    var serialization_error = false;
    
    const SerializationContext = struct {
        buffer: *std.ArrayList(u8),
        error_flag: *bool,
    };
    
    var ctx = SerializationContext{
        .buffer = &buffer,
        .error_flag = &serialization_error,
    };
    
    const writeToArrayList = struct {
        fn callback(string_ref: c.MlirStringRef, userData: ?*anyopaque) callconv(.C) void {
            const context = @as(*SerializationContext, @ptrCast(@alignCast(userData.?)));
            const data = c.fromStringRef(string_ref);

            // Debug: std.debug.print("MLIR serialization callback: appending {} bytes (total so far: {})\n", .{ data.len, context.buffer.items.len });

            // Add bounds checking to prevent buffer overflow
            if (data.len > 100 * 1024 * 1024) { // 100MB sanity check
                std.debug.print("ERROR: MLIR serialization data chunk too large: {} bytes\n", .{data.len});
                context.error_flag.* = true;
                return;
            }
            context.buffer.appendSlice(data) catch |err| {
                std.debug.print("ERROR: Failed to append MLIR data chunk of {} bytes: {}\n", .{ data.len, err });
                context.error_flag.* = true;
                return;
            };
        }
    }.callback;

    // Debug: std.debug.print("serializeMLIRModule: About to call mlirOperationPrint...\n", .{});
    // Add null checks
    const module_op = module.op();
    if (@intFromPtr(module_op.handle.ptr) == 0) {
        std.debug.print("ERROR: Module operation handle is null\n", .{});
        return error.NullModuleHandle;
    }

    c.mlirOperationPrint(module_op.handle, writeToArrayList, &ctx);
    // Debug: std.debug.print("serializeMLIRModule: mlirOperationPrint completed, buffer size: {}\n", .{buffer.items.len});
    
    // Check if any errors occurred during serialization
    if (serialization_error) {
        std.debug.print("ERROR: MLIR serialization failed due to callback errors\n", .{});
        buffer.deinit();
        return error.MLIRSerializationFailed;
    }
    
    const serialized = buffer.toOwnedSlice() catch |err| {
        std.debug.print("ERROR: Failed to convert buffer to owned slice: {}\n", .{err});
        return err;
    };
    std.debug.print("✓ Serialized MLIR module to {} bytes\n", .{serialized.len});
    return serialized;
}
