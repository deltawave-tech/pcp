{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17616d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f75841d8e90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.func import functional_call\n",
    "\n",
    "# In a notebook, __file__ is not defined. Use the current working directory as a proxy.\n",
    "REPO_ROOT = Path().resolve().parent\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "from nanochat.gpt import GPT, GPTConfig\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe7112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = GPTConfig(sequence_len=32, vocab_size=65, n_layer=2, n_head=4, n_kv_head=4, n_embd=64)\n",
    "model = GPT(cfg).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c1a447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56, 33, 32,  ..., 12, 60, 34],\n",
       "        [51,  1,  3,  ..., 42, 10, 48],\n",
       "        [25, 23, 21,  ..., 59, 47, 42],\n",
       "        ...,\n",
       "        [30, 45, 11,  ...,  2, 50, 34],\n",
       "        [20, 18, 27,  ..., 27, 61, 60],\n",
       "        [ 2, 28, 32,  ..., 24, 38, 52]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.randint(0, cfg.vocab_size, (64, 32), dtype=torch.int64)\n",
    "targets = torch.randint(0, cfg.vocab_size, (64, 32), dtype=torch.int64)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c19d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02254282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a498a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 32, 65])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9907d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 65])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.view(-1,logits.size(-1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2380eb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d2ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3279, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(idx)\n",
    "logits.size()\n",
    "\n",
    "l = F.cross_entropy(\n",
    "    logits.view(-1,logits.size(-1)),\n",
    "    targets.view(-1),\n",
    "    ignore_index = -1,\n",
    "    reduction='mean'\n",
    ")\n",
    "l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13f55f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3279, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pt = model(idx, targets)\n",
    "loss_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "196c2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(model.named_parameters())\n",
    "param_names = list(params.keys())\n",
    "param_values = list(params.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40e66eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(torch.nn.Module):\n",
    "    def __init__(self, base, names):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.names = names\n",
    "    def forward(self, *args):\n",
    "        params_dict = {n: p for n, p in zip(self.names, args[:-2])}\n",
    "        return functional_call(self.base, params_dict, (args[-2], args[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(torch.nn.Module):\n",
    "    def __init__(self, base, names):\n",
    "        super().__init__()\n",
    "        self.base = base\n",
    "        self.names = names\n",
    "    def forward(self, *args):\n",
    "        params_dict = {n: p for n, p in zip[tuple](self.names, args[:-2])}\n",
    "        return functional_call(self.base, params_dict, (args[-2], args[-1]))\n",
    "\n",
    "wrapper = Wrapper(model, param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbb3aac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_inputs = param_values + [idx, targets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ed2fbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'transformer.wte.weight': Parameter containing:\n",
       " tensor([[-1.1258, -1.1524, -0.2506,  ..., -1.2341,  1.8197, -0.5515],\n",
       "         [-0.5692,  0.9200,  1.1108,  ...,  1.1648,  0.9234,  1.3873],\n",
       "         [-0.8834, -0.4189, -0.8048,  ..., -0.9944, -1.1894, -1.1959],\n",
       "         ...,\n",
       "         [ 0.5901, -0.8325, -1.3715,  ...,  1.0564, -0.1504,  0.7420],\n",
       "         [ 0.7272, -0.2612,  0.0124,  ..., -3.0357, -1.7288,  0.6020],\n",
       "         [ 1.9476,  1.0077, -0.1007,  ..., -0.1173, -0.6841,  0.5988]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.0.attn.c_q.weight': Parameter containing:\n",
       " tensor([[-0.1147,  0.0432, -0.0319,  ...,  0.1144, -0.0859, -0.0636],\n",
       "         [ 0.0551,  0.0994,  0.1193,  ..., -0.0264,  0.0643,  0.0257],\n",
       "         [-0.1003,  0.0246,  0.0806,  ..., -0.0367,  0.0546,  0.0245],\n",
       "         ...,\n",
       "         [ 0.0677, -0.0634,  0.1034,  ...,  0.0205, -0.0545,  0.0246],\n",
       "         [-0.0467,  0.0415,  0.0165,  ...,  0.0725,  0.0490,  0.0046],\n",
       "         [-0.0042,  0.0554,  0.0177,  ..., -0.0344,  0.0206, -0.0600]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.0.attn.c_k.weight': Parameter containing:\n",
       " tensor([[-0.1024,  0.0631,  0.0999,  ...,  0.0542,  0.1158, -0.0164],\n",
       "         [ 0.0943, -0.0147,  0.1008,  ...,  0.0844, -0.0078, -0.0982],\n",
       "         [ 0.0927, -0.0092, -0.0451,  ...,  0.1060, -0.1182, -0.0503],\n",
       "         ...,\n",
       "         [-0.0222,  0.0039,  0.0103,  ...,  0.0570, -0.0787,  0.0505],\n",
       "         [-0.0007, -0.0031, -0.0924,  ..., -0.0371,  0.0761,  0.0535],\n",
       "         [ 0.0129,  0.0156, -0.0026,  ..., -0.0167, -0.0328,  0.0576]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.0.attn.c_v.weight': Parameter containing:\n",
       " tensor([[ 0.0985,  0.0013, -0.0969,  ...,  0.0768, -0.1044,  0.1173],\n",
       "         [ 0.1176,  0.0329, -0.0113,  ...,  0.0631,  0.0757,  0.1053],\n",
       "         [ 0.0331,  0.0954, -0.0335,  ..., -0.0698,  0.0563, -0.1197],\n",
       "         ...,\n",
       "         [-0.0078,  0.0073, -0.0878,  ...,  0.1118, -0.0064,  0.0380],\n",
       "         [ 0.0551, -0.0714, -0.0450,  ..., -0.1162,  0.1031,  0.0890],\n",
       "         [-0.0446,  0.0508,  0.0393,  ..., -0.0238, -0.0053, -0.1019]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.0.attn.c_proj.weight': Parameter containing:\n",
       " tensor([[ 0.1065,  0.0755,  0.0590,  ...,  0.0181,  0.0370, -0.1042],\n",
       "         [-0.0819, -0.1189,  0.0928,  ..., -0.0756, -0.0910, -0.0705],\n",
       "         [ 0.0002,  0.0535, -0.0041,  ..., -0.0163, -0.0616,  0.1132],\n",
       "         ...,\n",
       "         [-0.0451, -0.1106, -0.0994,  ..., -0.0977,  0.0723,  0.0231],\n",
       "         [-0.0345, -0.1049,  0.0902,  ...,  0.0231, -0.0761,  0.1087],\n",
       "         [ 0.0637, -0.0832, -0.0539,  ..., -0.0170, -0.0720,  0.0168]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.0.mlp.c_fc.weight': Parameter containing:\n",
       " tensor([[ 0.0031, -0.0615,  0.1119,  ..., -0.0836, -0.0452, -0.0770],\n",
       "         [ 0.0985, -0.1046, -0.0027,  ..., -0.0518,  0.0665,  0.0743],\n",
       "         [-0.1222,  0.0559,  0.0610,  ...,  0.0120,  0.0081, -0.0710],\n",
       "         ...,\n",
       "         [ 0.0413, -0.1015,  0.0498,  ...,  0.0654, -0.1207, -0.0758],\n",
       "         [-0.0871, -0.0438, -0.0543,  ..., -0.0726,  0.0739, -0.0936],\n",
       "         [-0.1113, -0.0314,  0.0294,  ..., -0.0940,  0.0714, -0.0386]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.0.mlp.c_proj.weight': Parameter containing:\n",
       " tensor([[ 0.0607,  0.0406,  0.0163,  ..., -0.0523, -0.0211, -0.0414],\n",
       "         [ 0.0229, -0.0359,  0.0580,  ...,  0.0267,  0.0382,  0.0502],\n",
       "         [ 0.0390,  0.0234, -0.0117,  ...,  0.0447, -0.0012,  0.0101],\n",
       "         ...,\n",
       "         [ 0.0431,  0.0315,  0.0479,  ...,  0.0283, -0.0245,  0.0024],\n",
       "         [ 0.0485, -0.0052,  0.0362,  ..., -0.0468,  0.0066, -0.0512],\n",
       "         [ 0.0485, -0.0178, -0.0554,  ...,  0.0564, -0.0144,  0.0093]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.1.attn.c_q.weight': Parameter containing:\n",
       " tensor([[-0.0302,  0.0467, -0.0331,  ..., -0.1049, -0.0118, -0.0519],\n",
       "         [ 0.0388,  0.0636,  0.0819,  ..., -0.0847,  0.0791, -0.0945],\n",
       "         [-0.0607, -0.0178,  0.0181,  ...,  0.0660, -0.0678, -0.0597],\n",
       "         ...,\n",
       "         [-0.1185,  0.0545,  0.0884,  ..., -0.0833, -0.0076,  0.0476],\n",
       "         [ 0.0818, -0.0617,  0.0303,  ..., -0.0308,  0.1024,  0.0775],\n",
       "         [ 0.0489,  0.0044,  0.0836,  ...,  0.0829, -0.0268,  0.0640]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.1.attn.c_k.weight': Parameter containing:\n",
       " tensor([[-0.0183,  0.0061, -0.0500,  ..., -0.0419, -0.0605,  0.0248],\n",
       "         [ 0.0279,  0.0558,  0.0187,  ...,  0.0987,  0.0012,  0.0152],\n",
       "         [-0.0573,  0.0556,  0.0553,  ..., -0.1015, -0.0419,  0.0528],\n",
       "         ...,\n",
       "         [-0.0425, -0.1025,  0.1135,  ..., -0.0970, -0.0727,  0.0880],\n",
       "         [ 0.0098,  0.1058,  0.1081,  ...,  0.0575,  0.1011,  0.1017],\n",
       "         [-0.0481,  0.0499, -0.0190,  ..., -0.0888,  0.1120, -0.0338]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.1.attn.c_v.weight': Parameter containing:\n",
       " tensor([[-0.0922,  0.0255, -0.0711,  ..., -0.1130,  0.0903,  0.1033],\n",
       "         [-0.0563,  0.1140, -0.0792,  ...,  0.0441, -0.1147,  0.0214],\n",
       "         [ 0.0309, -0.1156, -0.0911,  ..., -0.0598,  0.0640,  0.0852],\n",
       "         ...,\n",
       "         [-0.0823,  0.0726,  0.1095,  ...,  0.0074,  0.0728,  0.0176],\n",
       "         [-0.0514, -0.1178, -0.0752,  ..., -0.1199, -0.0160,  0.0538],\n",
       "         [-0.1221, -0.0994, -0.0708,  ...,  0.1006,  0.0621, -0.0310]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.1.attn.c_proj.weight': Parameter containing:\n",
       " tensor([[ 0.0265, -0.1059, -0.1059,  ...,  0.0242,  0.0271, -0.0544],\n",
       "         [-0.0313, -0.1158, -0.0066,  ...,  0.0209, -0.0776, -0.0479],\n",
       "         [-0.0117,  0.0009,  0.0536,  ...,  0.1164, -0.0235,  0.1106],\n",
       "         ...,\n",
       "         [ 0.0477,  0.0343, -0.0750,  ..., -0.1142,  0.1034, -0.0442],\n",
       "         [-0.1214, -0.0073,  0.0615,  ...,  0.0420,  0.0220, -0.0851],\n",
       "         [-0.0640, -0.0480, -0.0290,  ..., -0.0700,  0.0114,  0.1229]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.1.mlp.c_fc.weight': Parameter containing:\n",
       " tensor([[-0.1112, -0.0990,  0.0751,  ...,  0.0125,  0.0986,  0.0490],\n",
       "         [ 0.0856,  0.0858,  0.0605,  ..., -0.0493, -0.0661,  0.0373],\n",
       "         [-0.0983,  0.1085, -0.0013,  ...,  0.0128,  0.1136,  0.0466],\n",
       "         ...,\n",
       "         [ 0.1108,  0.0310,  0.0235,  ..., -0.0461, -0.0757,  0.0206],\n",
       "         [ 0.0694,  0.0072,  0.0728,  ..., -0.0369, -0.0253, -0.0175],\n",
       "         [ 0.0794,  0.1239, -0.0106,  ..., -0.1084, -0.1099, -0.0273]],\n",
       "        requires_grad=True),\n",
       " 'transformer.h.1.mlp.c_proj.weight': Parameter containing:\n",
       " tensor([[-0.0589,  0.0322, -0.0569,  ...,  0.0301, -0.0273, -0.0313],\n",
       "         [-0.0388, -0.0029,  0.0221,  ...,  0.0277, -0.0313,  0.0591],\n",
       "         [-0.0610,  0.0047,  0.0618,  ...,  0.0530, -0.0426, -0.0165],\n",
       "         ...,\n",
       "         [-0.0121, -0.0395,  0.0462,  ...,  0.0027, -0.0513,  0.0497],\n",
       "         [-0.0307, -0.0106, -0.0066,  ...,  0.0068,  0.0462,  0.0444],\n",
       "         [-0.0301,  0.0455,  0.0380,  ..., -0.0073, -0.0129, -0.0173]],\n",
       "        requires_grad=True),\n",
       " 'lm_head.weight': Parameter containing:\n",
       " tensor([[ 0.0124,  0.0148,  0.0454,  ...,  0.1040, -0.1113,  0.0857],\n",
       "         [ 0.0287,  0.0773, -0.0410,  ..., -0.0248, -0.0212, -0.0587],\n",
       "         [-0.0554, -0.0674,  0.0776,  ...,  0.0668, -0.0938, -0.0798],\n",
       "         ...,\n",
       "         [-0.0865, -0.0811, -0.1131,  ...,  0.0886, -0.1168, -0.0153],\n",
       "         [-0.1042,  0.0813, -0.0198,  ..., -0.1046,  0.0423,  0.0226],\n",
       "         [ 0.1196,  0.0488,  0.1011,  ...,  0.0754, -0.0297, -0.0504]],\n",
       "        requires_grad=True)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91b756ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000,   -inf,   -inf],\n",
       "        [0.3000, 0.4500,   -inf],\n",
       "        [0.9000, 1.2000, 1.5000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "q = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [0.5, 1.5, -0.5],\n",
    "                  [2.0, 0.0, 1.0]])\n",
    "v = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6],\n",
    "                  [0.7, 0.8, 0.9]])\n",
    "qv = q @ v\n",
    "qv\n",
    "tril = torch.tril(torch.ones(3,3).to('cpu'))\n",
    "att = qv.masked_fill(tril==0, float('-inf'))\n",
    "att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c32c4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.3499), tensor(1.5683))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.exp(torch.tensor(0.3000)), torch.exp(torch.tensor(0.4500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eabded4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9182)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor(0.3000)) + torch.exp(torch.tensor(0.4500))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c288c9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4626)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.tensor(0.3000)) / (torch.exp(torch.tensor(0.3000)) + torch.exp(torch.tensor(0.4500)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f60bf602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.4626, 0.5374, 0.0000],\n",
       "        [0.2397, 0.3236, 0.4368]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(att, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b72e08c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m softmax_qv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(qv, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq @ v =\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, qv)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax(q @ v) =\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, softmax_qv)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qv' is not defined"
     ]
    }
   ],
   "source": [
    "softmax_qv = torch.softmax(qv, dim=-1)\n",
    "print(\"q @ v =\\n\", qv)\n",
    "print(\"softmax(q @ v) =\\n\", softmax_qv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcp (venv)",
   "language": "python",
   "name": "pcp-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
